{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSAhIPcdfWvpOkE8gy64uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mspatke/Deep-Learning-with-Tensorflow/blob/main/iris_classification_ann.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Example - Iris\n",
        "\n",
        "This examples demonstrates the core deep learning model building concepts using the Keras library. The Iris flower dataset is used to build the model and perform classification tasks"
      ],
      "metadata": {
        "id": "dktNYi9gCs9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #install dependencies\n",
        "\n",
        "# !pip install pandas\n",
        "# !pip install tensorflow\n",
        "# !pip install sklearn\n",
        "# !pip install matplotlib"
      ],
      "metadata": {
        "id": "Y29amYddCToz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Prepare Input Data for Deep Learning\n",
        "\n",
        "Perform the following steps for preparing data\n",
        "\n",
        "1. Load data into a pandas dataframe\n",
        "2. Convert the dataframe to a numpy array\n",
        "3. Scale the feature dataset\n",
        "4. Use one-hot-encoding for the target variable\n",
        "5. Split into training and test datasets\n"
      ],
      "metadata": {
        "id": "cvpUh3eUD7zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Load Data and review content\n",
        "iris_data = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
        "print(iris_data.head())\n",
        "\n",
        "#Use a Label encoder to convert String to numeric values\n",
        "#for the target variable\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "iris_data['Species'] = label_encoder.fit_transform(iris_data['Species'])\n",
        "\n",
        "\n",
        "# convert input to numpy array\n",
        "np_iris = iris_data.to_numpy()\n",
        "\n",
        "#split feature and target data\n",
        "X_data = np_iris[:,0:4]\n",
        "Y_data = np_iris[:,4]\n",
        "\n",
        "print(\"\\nFeatures before scaling :\\n------------------------------------\")\n",
        "print(X_data[:5,:])\n",
        "print(\"\\nTarget before scaling :\\n------------------------------------\")\n",
        "print(Y_data[:5])\n",
        "\n",
        "#Create a scaler model that is fit on the input data.\n",
        "scaler = StandardScaler().fit(X_data)\n",
        "\n",
        "#Scale the numeric feature variables\n",
        "X_data = scaler.transform(X_data)\n",
        "\n",
        "#Convert target variable as a one-hot-encoding array\n",
        "Y_data = tf.keras.utils.to_categorical(Y_data,3)\n",
        "\n",
        "print(\"\\nFeatures after scaling :\\n------------------------------------\")\n",
        "print(X_data[:5,:])\n",
        "print(\"\\nTarget after one-hot-encoding :\\n------------------------------------\")\n",
        "print(Y_data[:5,:])\n",
        "\n",
        "#Split training and test data\n",
        "X_train,X_test,Y_train,Y_test = train_test_split( X_data, Y_data, test_size=0.10)\n",
        "\n",
        "print(\"\\nTrain Test Dimensions:\\n------------------------------------\")\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMKek6s3Dqkk",
        "outputId": "5b6a1786-9211-4d83-8252-905f87ba1e83"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded Data :\n",
            "------------------------------------\n",
            "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "Features before scaling :\n",
            "------------------------------------\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "\n",
            "Target before scaling :\n",
            "------------------------------------\n",
            "[0. 0. 0. 0. 0.]\n",
            "\n",
            "Features after scaling :\n",
            "------------------------------------\n",
            "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
            " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
            " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
            " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
            " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n",
            "\n",
            "Target after one-hot-encoding :\n",
            "------------------------------------\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "\n",
            "Train Test Dimensions:\n",
            "------------------------------------\n",
            "(135, 4) (135, 3) (15, 4) (15, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Creating a Model\n",
        "\n",
        "Creating a model in Keras requires defining the following\n",
        "\n",
        "1. Number of hidden layers\n",
        "2. Number of nodes in each layer\n",
        "3. Activation functions\n",
        "4. Loss Function & Accuracy measurements"
      ],
      "metadata": {
        "id": "eOvKDS9-FXK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n"
      ],
      "metadata": {
        "id": "2yBXHh-AE0mC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}